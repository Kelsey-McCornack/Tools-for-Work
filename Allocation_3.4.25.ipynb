{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to allocate scarce resources\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "Fix filter_portal_df - make sure canceled orders aren't being included.\n",
    "Include most recent order date in active df. Min date?\n",
    "Add qty on ready to\n",
    "Rearrange columns\n",
    "Append Ready To orders to Active\n",
    "Add header\n",
    "Reduce repetitive code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the date 6 months + 1 day ago. Use to filter completed record.\n",
    "six_months_ago = datetime.now() + relativedelta(months=-6, days=-1)\n",
    "print(six_months_ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open CSVs and convert to pandas dataframes\n",
    "dir_downloads = 'C:\\\\Users\\\\Purchasing_Kelsey\\\\Downloads\\\\'\n",
    "dir_taq = 'C:\\\\Users\\\\Purchasing_Kelsey\\\\Documents\\\\K\\'s Projects\\\\Taq Triage\\\\'\n",
    "dir_taq_records = 'C:\\\\Users\\\\Purchasing_Kelsey\\\\Documents\\\\K\\'s Projects\\\\Taq Triage\\\\Taq Records\\\\'\n",
    "\n",
    "files = [\n",
    "        'Active_Orders (14).csv',\n",
    "        'Ready_to_Order (19).csv',\n",
    "        'Completed (7).csv', # Past 6 months order history\n",
    "        'Taq_Summary_2024.csv'\n",
    "]\n",
    "try:\n",
    "        df_active = pd.read_csv(dir_downloads + files[0], index_col=None, header = 0)\n",
    "        df_ready_to = pd.read_csv(dir_downloads + files[1], index_col=None, header = 0)\n",
    "        df_complete_6mo = pd.read_csv(dir_downloads + files[2], index_col=None, header = 0)\n",
    "        df_summary_2024 = pd.read_csv(dir_taq_records + files[3], index_col=None, header = 0)\n",
    "\n",
    "except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date requested to datetime\n",
    "df_active['Date requested'] = pd.to_datetime(df_active['Date requested'])\n",
    "df_ready_to['Date requested'] = pd.to_datetime(df_ready_to['Date requested'])\n",
    "df_complete_6mo['Date requested'] = pd.to_datetime(df_complete_6mo['Date requested'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check filtering. To do - streamline. Fix min date check.\n",
    "print('df_active:', df_active['Status'].unique(), df_active['Vendor Requested'].unique(), df_active['Catalog No'].unique(), df_active['Status'].unique())\n",
    "print('df_ready_to:', df_ready_to['Status'].unique(), df_ready_to['Vendor Requested'].unique(), df_ready_to['Catalog No'].unique(), df_ready_to['Status'].unique())\n",
    "print('df_complete_6mo:', df_complete_6mo['Status'].unique(), df_complete_6mo['Vendor Requested'].unique(), df_complete_6mo['Catalog No'].unique(), df_complete_6mo['Status'].unique(), min(df_complete_6mo['Date requested']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "# function to filter dfs to keep only target items. Accepts a df and lists of vendors, cat nos, statsuses, and column names.\n",
    "def filter_portal_df(df, keep_vend, keep_cat, rm_stat):\n",
    "    try:\n",
    "        # Filter based on the provided lists\n",
    "        df = df[df['Vendor Requested'].isin(keep_vend)].copy()\n",
    "        df = df[df['Catalog No'].isin(keep_cat)].copy()\n",
    "        df = df[~df['Status'].isin(rm_stat)].copy()\n",
    "        \n",
    "        # Debugging: Print unique values for verification\n",
    "        print('Vendors: ', df['Vendor Requested'].unique())\n",
    "        print('Cat Nos: ', df['Catalog No'].unique())\n",
    "        print('Statuses: ', df['Status'].unique())\n",
    "\n",
    "        return df.copy()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# function to drop columns that aren't keys in a dict\n",
    "def drop_cols(df, keep_col_dict): \n",
    "    keep_col_list = list(keep_col_dict.keys())\n",
    "    drop_col = df.columns[~df.columns.isin(keep_col_list)]\n",
    "    df = df.drop(df[drop_col], axis=1)\n",
    "    return df.copy()\n",
    "\n",
    "def get_5_recent_orders(df):\n",
    "    try:\n",
    "        df_sorted = df.sort_values(by=['Lab ID', 'Date requested'], ascending=[True, False])\n",
    "\n",
    "        df_rec_ord = df_sorted.groupby('Lab ID').head(5)\n",
    "        df_rec_ord.head()\n",
    "        return df_rec_ord\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Function to filter df_completed to contain only orders for labs with pending Taq orders.\n",
    "# Accepts filtered Active Orders & filtered completed orders dfs\n",
    "def keep_target_labIDs(df_act, df_comp):\n",
    "    target_labs = df_act['Lab ID'].unique()\n",
    "    df_comp = df_comp[df_comp['Lab ID'].isin(target_labs)]\n",
    "    return df_comp.copy()\n",
    "\n",
    "# function to save to a given directory with a given name\n",
    "def save_to_csv(df, save_dir, save_name):\n",
    "    save_name = save_name + datetime.today().strftime('%m.%d.%Y') + \".csv\"\n",
    "    try:\n",
    "        df.to_csv(save_dir + save_name, encoding='utf-8', index=False)\n",
    "        print(save_name, \"saved\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Updated drop cols function\n",
    "def drop_cols_2(df, rm_col_list): \n",
    "    drop_col = df.columns[df.columns.isin(rm_col_list)]\n",
    "    df = df.drop(df[drop_col], axis=1)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists of values to keep and exclude\n",
    "keep_catnos = ['T-1012']\n",
    "\n",
    "rm_statuses = ['Canceled']\n",
    "\n",
    "keep_vendors = [\n",
    "    'DCW',\n",
    "    'DCW-K',\n",
    "    'DCWK',\n",
    "    'IEH Equipment'\n",
    "]\n",
    "\n",
    "keep_col_portal = {\n",
    "    'Date requested':'datetime',\n",
    "    'Lab ID':str,\n",
    "    'Vendor Requested':str,\n",
    "    'Product Name/Description':str,\n",
    "    'Catalog Number Requested':str,\n",
    "    'Quantity':int,\n",
    "    'Date Order Placed':'datetime',\n",
    "    'Tracking #':str,\n",
    "    'sheet':str,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Active df\n",
    "df_active = filter_portal_df(df_active, keep_vendors, keep_catnos, rm_statuses)\n",
    "df_active = drop_cols(df_active, keep_col_portal)\n",
    "df_active.head()\n",
    "\n",
    "#save_to_csv(df_active, dir_taq, 'TaqActive_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Ready To\n",
    "df_ready_to = filter_portal_df(df_ready_to, keep_vendors, keep_catnos, rm_statuses)\n",
    "df_ready_to = drop_cols(df_ready_to, keep_col_portal)\n",
    "df_ready_to.head()\n",
    "\n",
    "# save_to_csv(df_ready_to, dir_taq, 'TaqReadyTo_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df_complete_6mo\n",
    "df_complete_6mo = drop_cols(df_complete_6mo, keep_col_portal)\n",
    "#save_to_csv(df_complete_6mo, dir_taq, 'TaqCompleted6mo_')\n",
    "df_complete_6mo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a summary column\n",
    "df_active_total_qty = df_active[['Lab ID', 'Quantity']].copy()\n",
    "df_active_total_qty = df_active_total_qty.groupby('Lab ID').sum()\n",
    "df_active_total_qty.head()\n",
    "\n",
    "df_active_oldest_date = df_active[['Lab ID', 'Date requested']].copy()\n",
    "df_active_oldest_date = df_active.groupby('Lab ID')['Date requested'].min()\n",
    "df_active_oldest_date.head()\n",
    "\n",
    "df_active_summary = pd.merge(df_active_total_qty, df_active_oldest_date, how = 'left', on='Lab ID')\n",
    "df_active_summary['sheet'] = 'Active'\n",
    "\n",
    "df_active_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready_to_total_qty = df_ready_to[['Lab ID', 'Quantity']].copy()\n",
    "df_ready_to_total_qty = df_ready_to_total_qty.groupby('Lab ID').sum()\n",
    "df_ready_to_total_qty.head()\n",
    "\n",
    "df_ready_to_oldest_date = df_ready_to[['Lab ID', 'Date requested']].copy()\n",
    "df_ready_to_oldest_date = df_ready_to_oldest_date.groupby('Lab ID')['Date requested'].min()\n",
    "df_ready_to_oldest_date.head()\n",
    "df_ready_to_summary = pd.merge(df_ready_to_total_qty, df_ready_to_oldest_date, how = 'left', on='Lab ID')\n",
    "df_ready_to_summary['sheet'] = 'Ready to'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append summary dfs to each other\n",
    "df_pending_summary = pd.concat([df_active_summary, df_ready_to_summary])\n",
    "df_pending_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 6 Month Summary\n",
    "df_6mo_summary = df_complete_6mo[['Lab ID', 'Quantity']].copy()\n",
    "df_6mo_summary = df_6mo_summary.groupby('Lab ID').sum()\n",
    "\n",
    "df_6mo_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "df_merge = df_pending_summary.merge(df_summary_2024, how = 'left', on = 'Lab ID')\n",
    "df_merge = df_merge.merge(df_6mo_summary, how = 'left', on = 'Lab ID')\n",
    "df_merge.head()\n",
    "\n",
    "df_merge = df_merge.rename(columns={'Quantity_x':'Qty', 'Quantity_y':'6mo Total'})\\\n",
    "\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated columns\n",
    "df_merge['% Filled'] = df_merge['6mo Total']/(df_merge['Total Qty 2024']/2)\n",
    "\n",
    "df_merge = df_merge.sort_values(by='% Filled')\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make final df\n",
    "df_final = df_merge[['Lab ID','sheet', 'Monthly Avg', '% Filled', 'Qty', ]].copy()\n",
    "df_final['Send Qty'] = ''\n",
    "df_final['Lab Emailed?'] = ''\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(df_final, dir_taq, 'Summary_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
